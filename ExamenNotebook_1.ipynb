{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hoofdstuk 1\n",
        "importing dataset through github"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "b9P7yHCZZgSK"
      },
      "outputs": [],
      "source": [
        "# Importing the necessary packages\n",
        "import numpy as np                                  # \"Scientific computing\"\n",
        "import scipy.stats as stats                         # Statistical tests\n",
        "\n",
        "import pandas as pd                                 # Data Frame\n",
        "from pandas.api.types import CategoricalDtype\n",
        "\n",
        "import matplotlib.pyplot as plt                     # Basic visualisation\n",
        "from statsmodels.graphics.mosaicplot import mosaic  # Mosaic diagram\n",
        "import seaborn as sns                               # Advanced data visualisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Os8nf1l-Hv8p"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  \\\n",
              "0            1         0       3   \n",
              "1            2         1       1   \n",
              "2            3         1       3   \n",
              "3            4         1       1   \n",
              "4            5         0       3   \n",
              "\n",
              "                                                Name     Sex   Age  SibSp  \\\n",
              "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
              "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
              "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
              "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
              "4                           Allen, Mr. William Henry    male  35.0      0   \n",
              "\n",
              "   Parch            Ticket     Fare Cabin Embarked  \n",
              "0      0         A/5 21171   7.2500   NaN        S  \n",
              "1      0          PC 17599  71.2833   C85        C  \n",
              "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
              "3      0            113803  53.1000  C123        S  \n",
              "4      0            373450   8.0500   NaN        S  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "titanic = pd.read_csv('https://raw.githubusercontent.com/DataRepo2019/Data-files/master/titanic.csv')\n",
        "# Show the first few records of the Data Frame\n",
        "titanic.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "649PvEm3IOfS"
      },
      "source": [
        "Setting index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Ma50hjOPIRJa"
      },
      "outputs": [],
      "source": [
        "titanic = titanic.set_index(['PassengerId'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b450mDi4IUPK"
      },
      "source": [
        "Converting to nominale of ordinale dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6EFLKRrVIaP6"
      },
      "outputs": [],
      "source": [
        "# Convert to a categorical variable\n",
        "titanic.Survived = titanic.Survived.astype('category')\n",
        "# Convert to a Ordinale variable\n",
        "embarked_type = CategoricalDtype(categories=['S', 'C', 'Q'], ordered=True)\n",
        "titanic.Embarked = titanic.Embarked.astype(embarked_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zY4j45vVwK3A"
      },
      "source": [
        "## Berekeningen + setting up data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAelAOGqxmSU"
      },
      "source": [
        "### Berekeningen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gXJJ9sVwN0m"
      },
      "outputs": [],
      "source": [
        "##Berekeningen\n",
        "print(f\"Unieke waarde :   {titanic['Sex'].unique()}\")\n",
        "print(f\"describe :   {titanic.Survived.describe()}\")\n",
        "# How many  rows does the DataFrame have?\n",
        "print(f\"Number of rows: {len(titanic)}\")\n",
        "# How many columns?\n",
        "print(f\"Number of columns: {len(titanic.columns)}\")\n",
        "# How many rows and columns, i.e. the shape\n",
        "print(f\"The shape of the Data Frame is: {titanic.shape}\")\n",
        "# General information about the DataFrame\n",
        "\n",
        "print(f\"info :   {titanic.info()}\")\n",
        "# Give the data type of each column.\n",
        "\n",
        "print(f\"dtypes :   {titanic.dtypes}\")\n",
        "# How many columns of each data type are there?\n",
        "#   Watch it! The book says to use get_dtype_counts(), but this method no longer exists\n",
        "print(titanic.dtypes.value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VKCTcOHxo6D"
      },
      "source": [
        "### Setting up data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8QywvZ2xqlc"
      },
      "outputs": [],
      "source": [
        "##Setting up data\n",
        "titanic = titanic.dropna() # Drop any row that has at least one missing value\n",
        "###replacing\n",
        "titanic.Height = titanic.Height.str.replace(',','').astype(float)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snfAFRKAdBDi"
      },
      "source": [
        "# Hoofdstuk 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiPspulMvfX9"
      },
      "source": [
        "## Berekeningen van spreidingsmaten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PV9pumErdFnL"
      },
      "outputs": [],
      "source": [
        "# Centrality and dispersion deasures\n",
        "# Mean, standard deviation & friends\n",
        "print(f\"Mean:                {tips['tip'].mean()}\")\n",
        "print(f\"Standard deviation:  {tips['tip'].std()}\") # Pay attention: n-1 in the denominator\n",
        "print(f\"Variance:            {tips['tip'].var()}\") # Pay attention: n-1 in the denominator\n",
        "print(f\"Skewness:            {tips['tip'].skew()}\")\n",
        "print(f\"Kurtosis:            {tips['tip'].kurtosis()}\")\n",
        "\n",
        "# Median & co\n",
        "print(f\"Minimum:   {tips['tip'].min()}\")\n",
        "print(f\"Median:    {tips['tip'].median()}\")\n",
        "print(f\"Maximum:   {tips['tip'].max()}\")\n",
        "percentiles = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
        "print(\"Percentiles\", percentiles, \"\\n\", tips['tip'].quantile(percentiles))\n",
        "print(\"Inter Quartile Range:\", tips['tip'].quantile(.75) - tips['tip'].quantile(.25))\n",
        "print(f\"Range :    {tips['tip'].max() - tips['tip'].min()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jTWHpBXupp2"
      },
      "source": [
        "## Visualisatie"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a38289f"
      },
      "source": [
        "## Qualitative Variables\n",
        "\n",
        "### Visualisation using a Bar Chart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "3d00c931",
        "outputId": "f96cae9e-e713-4451-c8f2-bbffbd43bbc9"
      },
      "outputs": [],
      "source": [
        "# Bar chart in Seaborn: catplot() with 'kind = \"count\"''\n",
        "sns.catplot(data = tips, kind = \"count\", y = \"day\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePk_ETDvvEE1"
      },
      "source": [
        "## Quantitative Variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9M9qNzcvIgJ"
      },
      "source": [
        "### Boxplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIqXC8k4vHrd"
      },
      "outputs": [],
      "source": [
        "# Visualisation using a box plot (Seaborn)\n",
        "sns.boxplot(data = tips, x = \"tip\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L044as2jvMy0"
      },
      "source": [
        "### Histogram met of zonder KDE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GoTxVti1vMy7"
      },
      "outputs": [],
      "source": [
        "#Met KDE\n",
        "sns.displot(x = tips['tip'], kde=True);\n",
        "\n",
        "#Zonder KDE\n",
        "sns.displot(x = tips['tip'], kde=True);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwSUjgCAFJez"
      },
      "source": [
        "# Hoofdstuk 3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_DAbY8wFVNW"
      },
      "source": [
        "## Ploting normaal verdeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1zgwY7UFULa"
      },
      "outputs": [],
      "source": [
        "mu = 0    # Mean\n",
        "sigma = 1  # Standard deviation\n",
        "x = np.linspace(mu - 4 * sigma, mu + 4 * sigma, num=201)\n",
        "y = stats.norm.pdf(x, mu, sigma)\n",
        "plt.plot(x, y)\n",
        "plt.title(\"Standard Normal Distribution\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VD8JCVQF3ZR"
      },
      "source": [
        "## betrouwbaarheidsintervallen\n",
        "### n>=30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3RSlWerGR6I"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "# Step 1.\n",
        "m = 324.6      # Sample mean\n",
        "s = 2.5      # Population standard deviation\n",
        "n = 45      # Sample size\n",
        "alpha = .05  # 1 - alpha is the confidence level\n",
        "\n",
        "# Step 2.\n",
        "z = stats.norm.isf(alpha/2)\n",
        "print(\"z-score: %.5f\" % z)\n",
        "\n",
        "# Step 3.\n",
        "lo = m - z * s / np.sqrt(n)\n",
        "hi = m + z * s / np.sqrt(n)\n",
        "print(\"Confidence interval: [%.4f, %.4f]\" % (lo, hi))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1Q7xi-0GTOv"
      },
      "source": [
        "### n<30\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btLjqW9PGWB2"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "# Step 1.\n",
        "m = 324.6      # Sample mean\n",
        "s = 2.5      # Population standard deviation\n",
        "n = 15      # Sample size\n",
        "alpha = .05  # 1 - alpha is the confidence level\n",
        "\n",
        "# Step 2.\n",
        "t = stats.t.isf(alpha/2, df = n - 1)\n",
        "print(\"t-score: %.5f\" % t)\n",
        "\n",
        "# Step 3.\n",
        "lo = m - t * s / np.sqrt(n)\n",
        "hi = m + t * s / np.sqrt(n)\n",
        "print(\"Confidence interval: [%.4f, %.4f]\" % (lo, hi))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QodmjhzDG85X"
      },
      "source": [
        "## Hypothese testen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### $z$-tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMUvY3lfG_S3"
      },
      "source": [
        "### Right tailed Z-Test\n",
        "**Step 1.** Formulate the hypotheses:\n",
        "\n",
        "- $H_0: \\mu = 3.3$\n",
        "- $H_1: \\mu > 3.3$\n",
        "\n",
        "**Step 2.** Choose a significance level, e.g. $\\alpha = 0.05$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pbzgvy_uFH3v"
      },
      "outputs": [],
      "source": [
        "# Properties of the sample:\n",
        "n = 30      # sample size\n",
        "sm = 3.483  # sample mean\n",
        "s = 0.55    # population standard deviation (assumed to be known)\n",
        "a = 0.05    # significance level (chosen by the researcher)\n",
        "m0 = 3.3    # hypothetical population mean (H0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBGdecKIFH3w"
      },
      "source": [
        "**Step 3.** Determine the value of the test statistic, in this case $\\overline{x} = 3.483$\n",
        "\n",
        "**Step 4.** Determine the $p$-value and reject $H_0$ if $p < \\alpha$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5CGeZRPFH3x"
      },
      "outputs": [],
      "source": [
        "p = stats.norm.sf(sm, loc=m0, scale=s/np.sqrt(n))\n",
        "print(\"p-value: %.5f\" % p)\n",
        "if(p < a):\n",
        "    print(\"p < a: reject H0\")\n",
        "else:\n",
        "    print(\"p > a: do not reject H0\")\n",
        "    \n",
        "# Critical value according to the formula in the lecture slides\n",
        "#g = m0 + stats.norm.isf(a) * s / np.sqrt(n)         \n",
        "# Making use of the loc/scale parameters of isf:\n",
        "g = stats.norm.isf(a, loc=m0, scale=s / np.sqrt(n)) #\n",
        "print(\"Critical value g ≃ %.3f\" % g)\n",
        "if (sm < g):\n",
        "    print(\"sample mean = %.3f < g = %.3f: do not reject H0\" % (sm, g))\n",
        "else:\n",
        "    print(\"sample mean = %.3f > g = %.3f: reject H0\" % (sm, g))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5APyf2pHr9I"
      },
      "source": [
        "### Left-tailed Z-test\n",
        "\n",
        "**Step 1.** Formulate the hypotheses:\n",
        "\n",
        "- $H_0: \\mu = 3.3$\n",
        "- $H_1: \\mu < 3.3$\n",
        "\n",
        "**Step 2.** Choose significance level, e.g. $\\alpha = 0.05$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96t9fZoPFH32"
      },
      "outputs": [],
      "source": [
        "# Properties of the sample:\n",
        "n = 30      # sample size\n",
        "sm = 3.117  # sample mean\n",
        "s = 0.55    # population standard deviation (assumed to be known)\n",
        "a = 0.05    # significance level (chosen by the researcher)\n",
        "m0 = 3.3    # hypothetical population mean (H0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6KtlzWsFH32"
      },
      "source": [
        "**Step 3.** Calculate the test statistic: $\\overline{x} = 3.117$\n",
        "\n",
        "**Step 4.** Determine the $p$-value and reject $H_0$ if $p < \\alpha$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TryiL-8cFH33"
      },
      "outputs": [],
      "source": [
        "p = stats.norm.cdf(sm, loc=m0, scale=s/np.sqrt(n)) # Let op! cdf() ipv sf()!\n",
        "print(\"p-waarde: %.5f\" % p)\n",
        "if(p < a):\n",
        "    print(\"p < a, dus H0 verwerpen\")\n",
        "else:\n",
        "    print(\"p > a, dus H0 niet verwerpen\")\n",
        "    \n",
        "# Critical value according to the formula in the lecture slides\n",
        "# g = m0 - stats.norm.isf(a) * s / np.sqrt(n)\n",
        "# Making use of the loc/scale parameters of isf:\n",
        "g = stats.norm.isf(1-a, loc=m0, scale=(s / np.sqrt(n)))\n",
        "print(\"Critical value g ≃ %.3f\" % g)\n",
        "if (sm > g):\n",
        "    print(\"sample mean = %.3f > g = %.3f: do not reject H0\" % (sm, g))\n",
        "else:\n",
        "    print(\"sample mean = %.3f < g = %.3f: reject H0\" % (sm, g))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAn2S1AMFH34"
      },
      "source": [
        "### The two-tailed $z$-test\n",
        "\n",
        "When we don't want to test whether the population mean is either greater or lower than a hypothetical value, but only want to know if the sample mean is \"close enough\", we can use a two-tailed $z$-test.\n",
        "\n",
        "**Step 1.** Formulate the hypotheses:\n",
        "\n",
        "- $H_0: \\mu = 3.3$\n",
        "- $H_1: \\mu \\ne 3.3$\n",
        "\n",
        "**Step 2.** Choose significance level, e.g. $\\alpha = 0.05$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-fdnMEoFH35"
      },
      "outputs": [],
      "source": [
        "# Properties of the sample:\n",
        "n = 30      # sample size\n",
        "sm = 3.483  # sample mean\n",
        "s = 0.55    # population standard deviation (assumed to be known)\n",
        "a = 0.05    # significance level (chosen by the researcher)\n",
        "m0 = 3.3    # hypothetical population mean (H0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iK4LsoiLFH35"
      },
      "source": [
        "**Step 3.** Determine the test statistic $\\overline{x} = 3.483$\n",
        "\n",
        "**Step 4.** Calculate the $p$-value and reject $H_0$ if $p < \\alpha/2$ (why do we divide by 2?)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxkggGAiFH35"
      },
      "outputs": [],
      "source": [
        "p = stats.norm.sf(sm, loc=m0, scale=s/np.sqrt(n))\n",
        "print(\"p-waarde: %.5f\" % p)\n",
        "if(p < a/2):\n",
        "    print(\"p < a/2, dus H0 verwerpen\")\n",
        "else:\n",
        "    print(\"p > a/2, dus H0 niet verwerpen\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IccMNG0FH36"
      },
      "source": [
        "In this case, we have two critical values: $g_1$ on the left of the mean and $g_2$ on the right. The acceptance region still has area $1-\\alpha$ and the critical region has area $\\alpha$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PKApys1FH36"
      },
      "outputs": [],
      "source": [
        "g1 = m0 - stats.norm.isf(a/2) * s / np.sqrt(n)\n",
        "g2 = m0 + stats.norm.isf(a/2) * s / np.sqrt(n)\n",
        "\n",
        "print(\"Acceptance region [g1, g2] ≃ [%.3f, %.3f]\" % (g1,g2))\n",
        "if (g1 < sm and sm < g2):\n",
        "    print(\"Sample mean = %.3f is inside acceptance region: do not reject H0\" % sm)\n",
        "else:\n",
        "    print(\"Sample mean = %.3f is outside acceptance region: reject H0\" % sm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## $t$-tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XW2emNfGFH37"
      },
      "source": [
        "\n",
        "### Right-tailed $t$-test\n",
        "\n",
        "**Step 1.** Formulate the hypotheses:\n",
        "\n",
        "- $H_0: \\mu = 3.3$\n",
        "- $H_1: \\mu > 3.3$\n",
        "\n",
        "**Step 2.** Choose significance level, e.g. $\\alpha = 0.05$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KnRAbC91FH37"
      },
      "outputs": [],
      "source": [
        "# Properties of the sample:\n",
        "n = 20      # sample size\n",
        "sm = 3.483  # sample mean\n",
        "ss = 0.55   # sample(!) standard deviation\n",
        "a = 0.05    # significance level (chosen by the researcher)\n",
        "m0 = 3.3    # hypothetical population mean (H0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBGTz5GvFH38"
      },
      "source": [
        "**Step 3.** Determine the test statistic $\\overline{x} = 3.483$\n",
        "\n",
        "**Step 4.** Calculate the $p$-value and reject $H_0$ if $p < \\alpha$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLCbGCXVFH38"
      },
      "outputs": [],
      "source": [
        "# Remark that we use the t-distribution here!\n",
        "p = p = stats.t.sf(sm, loc=m0, scale=ss/np.sqrt(n), df=n-1)\n",
        "print(\"p-value: %.5f\" % p)\n",
        "if(p < a):\n",
        "    print(\"p < a: reject H0\")\n",
        "else:\n",
        "    print(\"p > a: do not reject H0\") \n",
        "g = stats.t.isf(a, loc=m0, scale=ss/np.sqrt(n), df=n-1)\n",
        "print(\"Critical value g ≃ %.3f\" % g)\n",
        "if (sm < g):\n",
        "    print(\"sample mean = %.3f < g = %.3f: do not reject H0\" % (sm, g))\n",
        "else:\n",
        "    print(\"sample mean = %.3f > g = %.3f: reject H0\" % (sm, g))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IYODem-GLMj"
      },
      "source": [
        "# Hoofstuk 4: 2 kwalitatieve variabelen\n",
        "\n",
        "\n",
        "### $\\chi^2$ + cramers-v\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdA9wq6n7o7J"
      },
      "source": [
        "1. Formulate the hypotheses:\n",
        "   - $H_0$: There is no association between the variables (the differences between observed and expected values are small)\n",
        "   - $H_1$: There is an association between the variables (the differences are large)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrpXdgGFGclx"
      },
      "outputs": [],
      "source": [
        "alpha = 0.05\n",
        "observed = pd.crosstab(wijn.Muziek, wijn.Wijn)\n",
        "row_sums = observed.sum(axis=1)\n",
        "col_sums = observed.sum()\n",
        "n = row_sums.sum()\n",
        "chi2, p, dof, expected = stats.chi2_contingency(observed)\n",
        "\n",
        "print(\"Chi-squared       : %.4f\" % chi2)\n",
        "print(\"Degrees of freedom: %d\" % dof)\n",
        "print(\"P-value           : %.4f\" % p)\n",
        "\n",
        "cramers_v = np.sqrt(chi2 / ((min(observed.shape)-1) * n))\n",
        "print('Cramers-V:',cramers_v)\n",
        "g = stats.chi2.isf(alpha, df=dof)\n",
        "print('g-value:', g)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIGkDy0UNq5M"
      },
      "source": [
        "To draw a conclusion from the cramer-v, compare it with the values in the table below:\n",
        "\n",
        "| Cramér's V | Interpretation          |\n",
        "| :---:      | :---                    |\n",
        "| 0          | No association          |\n",
        "| 0.1        | Weak association        |\n",
        "| 0.25       | Moderate association    |\n",
        "| 0.50       | Strong association      |\n",
        "| 0.75       | Very strong association |\n",
        "| 1          | Complete association    |\n",
        "\n",
        "conclusie 𝜒2, g, p en alpha:\n",
        "\n",
        "| uitkomst | Interpretation          |\n",
        "| :---:      | :---                    |\n",
        "| 𝜒2< 𝑔       |do not reject H0          |\n",
        "| 𝜒2> 𝑔       | reject 𝐻0       |\n",
        "| 𝑝 > 𝛼      | do not reject 𝐻0    |\n",
        "| 𝑝 < 𝛼      | reject 𝐻     |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXKq8k9rTaht"
      },
      "source": [
        "### Stacked bar chart\n",
        "Another way to visualize the data is by stacking the bars instead of clustering them. Unfortunately, Seaborn doesn't provide us with a convenient method to do so. However, a crosstab object (actually a Pandas DataFrame) has a plot method that we can use. Remark that we swapped the variables when calling the crosstab function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2woU3YI3TYT1"
      },
      "outputs": [],
      "source": [
        "# Contingency table without the margins - Chi Squared\n",
        "observed = pd.crosstab(rlanders.Gender, rlanders.Survey)\n",
        "\n",
        "# Horizontally oriented stacked bar chart - Goodness of Fit Test\n",
        "observed.plot(kind='barh', stacked=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HONgwwiglRJJ"
      },
      "source": [
        "### countplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3FfPWvAOlWeI"
      },
      "outputs": [],
      "source": [
        "sns.countplot(data = products, x = 'Choice')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnI7OEfA8cyy"
      },
      "source": [
        "\n",
        "## Goodness-of-fit test\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xz16CFnz8rAa"
      },
      "source": [
        "1. Formulate the hypotheses:\n",
        "   - $H_0$: The sample is representative of the population, i.e. the frequency of each class within the sample corresponds well to that in the population.\n",
        "   - $H_1$: The sample is *not* representative of the population, i.e. the differences with the expected frequencies are too large."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cimwLKE9nFAJ"
      },
      "outputs": [],
      "source": [
        "types =               ['mutant', 'human', 'alien', 'god', 'demon']\n",
        "observed =   np.array([   127,      75,      98,     27,     73])\n",
        "expected_p = np.array([   .35,     .17,     .23,    .08,    .17])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3JhHUGC8w5C"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "alpha = 0.05               # Significance level\n",
        "n = sum(observed)          # Sample size\n",
        "k = len(observed)          # Number of categories\n",
        "dof = k - 1                # Degrees of freedom\n",
        "expected = expected_p * n  # Expected absolute frequencies in the sample\n",
        "g = stats.chi2.isf(alpha, df=dof)  # Critical value\n",
        "\n",
        "# Goodness-of-fit-test in Python:\n",
        "chi2, p = stats.chisquare(f_obs=observed, f_exp=expected)\n",
        "\n",
        "print(\"Significance level  ⍺ = %.2f\" % alpha)\n",
        "print(\"Sample size         n = %d\" % n)\n",
        "print(\"k = %d; df = %d\" % (k, dof))\n",
        "print(\"Chi-squared        χ² = %.4f\" % chi2)\n",
        "print(\"Critical value      g = %.4f\" % g)\n",
        "print(\"p-value             p = %.4f\" % p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbsOAXKWJTwF"
      },
      "source": [
        "## Cochran's rule\n",
        "\n",
        "A chi-squared test can only give good results if you have enough observations in each category. The statistician Cochran (1954) formulated a rule of thumb to determine what exactly *enough* is on contingency tables larger than 2x2:\n",
        "\n",
        "- All expected values must be at least 1\n",
        "- At most 20% of the expected values may be smaller than 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwrMb6J8eUWA"
      },
      "source": [
        "# Hoofdstuk 5\n",
        "\n",
        "## The 2 sample t-test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PQ2EJy6JvfE"
      },
      "source": [
        "\n",
        "The hypotheses are:\n",
        "\n",
        "- $H_0$: $\\mu_1 - \\mu_2 = 0$ (reaction time is the same in both groups)\n",
        "- $H_1$: $\\mu_1 - \\mu_2 < 0$ (reaction time is significantly higher in the treatment group compared to the control group)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUWFIe5JehGI"
      },
      "outputs": [],
      "source": [
        "stats.ttest_ind(a=control, b=treatment,\n",
        "    alternative='less', equal_var=False)\n",
        "\n",
        "#mogelijke waarden voor alternative = greater, less, two-sided"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QxjR3UPemVv"
      },
      "source": [
        "## The t-test for paired samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0v3g2HrdJ0E9"
      },
      "source": [
        "\n",
        "The hypotheses are:\n",
        "\n",
        "- $H_0$: $\\mu_1 - \\mu_2 = 0$ (reaction time is the same in both groups)\n",
        "- $H_1$: $\\mu_1 - \\mu_2 < 0$ (reaction time is significantly higher in the treatment group compared to the control group)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJoHEVjMesqP"
      },
      "outputs": [],
      "source": [
        "# Paired t-test with ttest_rel()\n",
        "statistic, pvalue = stats.ttest_rel(regular, additives, alternative='less')\n",
        "print(f'p-waarde is: ', pvalue)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a33QgNhJGTF"
      },
      "source": [
        "conclusie p en alpha:\n",
        "\n",
        "| uitkomst | Interpretation          |\n",
        "| :---:      | :---                    |\n",
        "| 𝑝 > 𝛼      | do not reject 𝐻0    |\n",
        "| 𝑝 < 𝛼      | reject 𝐻0     |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dO6Vnae1e2EY"
      },
      "source": [
        "## Cohen's  d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLnctrbCe-FA"
      },
      "outputs": [],
      "source": [
        "def cohen_d(a, b):\n",
        "    na = len(a)\n",
        "    nb = len(b)\n",
        "    pooled_sd = np.sqrt( ((na-1) * a.std(ddof=1)**2 +\n",
        "                          (nb-1) * b.std(ddof=1)**2) / (na + nb - 2) )\n",
        "    return (b.mean() - a.mean()) / pooled_sd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzbvjR0BfD44"
      },
      "outputs": [],
      "source": [
        "cohen_d(regular, additives)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrPoAxj9Mg4u"
      },
      "source": [
        "| Cohen's D| Effect size          |\n",
        "| :---:      | :---                    |\n",
        "| 0.01          | Very small         |\n",
        "| 0.2        | Small       |\n",
        "| 0.5       | Average    |\n",
        "| 0.8       | Large      |\n",
        "| 1.2       | Very Large |\n",
        "| 2         | Huge    |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N53awxf5dkDr"
      },
      "source": [
        "#### visualisatie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Bp85dnSdjMW"
      },
      "outputs": [],
      "source": [
        "sns.barplot(data=tips, x='sex', y='tip', ci='sd');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-WdCn4YeBkO"
      },
      "outputs": [],
      "source": [
        "sns.barplot(data=[temperatures.time1,temperatures.time2] , errorbar='sd');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6MEK_IT2Zmk"
      },
      "source": [
        "# Hoofdstuk 6: 2 kwantitatieve variabelen\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9l_1JtPH2kda"
      },
      "source": [
        "### Scatterplot tekenen\n",
        "The independent variable should be mapped to the X-axis, the dependent variable to the Y-axis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1BhCi492n27"
      },
      "outputs": [],
      "source": [
        "# Zonder regressie rechte\n",
        "sns.relplot(data=penguins,\n",
        "            x='bill_depth_mm', y='bill_length_mm',\n",
        "            size='body_mass_g', \n",
        "            hue='species', style='sex')\n",
        "\n",
        "# Met regressie rechte\n",
        "sns.regplot(x=male_chinstrap.flipper_length_mm, y=male_chinstrap.body_mass_g)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUKnTveG4TiG"
      },
      "source": [
        "## berekenen van de regressie rechte $$\\hat{y} = \\beta_0 + \\beta_1 x.$$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajPeufN94Xl_"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "x = male_chinstrap.flipper_length_mm.values.reshape(-1,1)\n",
        "y = male_chinstrap.body_mass_g\n",
        "\n",
        "model = LinearRegression().fit(x, y)\n",
        "\n",
        "print(f\"Regression line: ŷ = {model.intercept_:.2f} + {model.coef_[0]:.2f} x\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Ubbmeq9YAbc"
      },
      "outputs": [],
      "source": [
        "## predictie voor model voor waarde x = 2035\n",
        "print(model.predict([[2035]])[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1SViUxMKV-Y"
      },
      "source": [
        "## Coverance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AI-9SpJNKZkZ"
      },
      "outputs": [],
      "source": [
        "np.cov(families.x, families.y, ddof=1)[0][1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4UhwyUaKpEQ"
      },
      "source": [
        "## Correlatie coefficient + coeffienct van determinatie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVroPZlrKj1X"
      },
      "outputs": [],
      "source": [
        "# Python function numpy.corrcoef() - returns a matrix, like numpy.cov()\n",
        "# correlatie coefficient\n",
        "cor = np.corrcoef(families.x, families.y)[0][1]\n",
        "print(f\"R = {cor}\")\n",
        "\n",
        "#Coefficient van determinatie\n",
        "print(f'Coefficient van determinatie: ' , cor**2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lx-4VJOpL-3Z"
      },
      "source": [
        "| R| interpretatie scatterplot        | verband |\n",
        "| :---:      | :---                    |:---                    |\n",
        "| dichtbij 1 of -1          | punten op scatterplot liggen dicht bij de rechte         | sterk | \n",
        "| dichtbij 0       | punten op scatterplot liggen ver van de rechte         | zwak |\n",
        "\n",
        "\n",
        "| R| interpretatie rechte       |\n",
        "| :---:      | :---                    |\n",
        "| R > 0          | stijgend verband        |\n",
        "| R < 0          | dalend verband        |\n",
        "| R = 0          | geen verband        |\n",
        "\n",
        "\n",
        "| abs(R)| R^2| interpretatie verband       |\n",
        "| :---:      | :---                    | :---                    |\n",
        "| < 0.3         | < 0.1| very weak        |\n",
        "| 0.3 - 0.5        | 0.1 - 0.25|weak        |\n",
        "| 0.5 - 0.7          | 0.25 - 0.5|moderate       |\n",
        "| 0.7 - 0.85          | 0.5 - 0.75 |strong       |\n",
        "| 0.85 - 0.95         | 0.75 - 0.9 |very strong       |\n",
        "| > 0.95          | >0.9 | exceptional        |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltM2NcmPOgAB"
      },
      "source": [
        "uitschrijven van conclusie\n",
        "\n",
        "$R$ ~ 0.8 => een stijgend verband want $R$ > 0 en er is sterk verband tussen Hwt en Bwt (want 0.8)\n",
        "<Br>\n",
        "$R^2$ ~ 0.64 => een sterk verband + 64% van de variantie van de afh veranderlijke wordt verklaard door de onafh veranderlijke\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8lHaSUS1xyF"
      },
      "source": [
        "# Hoofdstuk 7: tijdserieanalyse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6DPWoet2hky"
      },
      "source": [
        "## ploting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsFz6lPv2js1"
      },
      "outputs": [],
      "source": [
        "data.plot(y=['number_of_heavily_wounded'], figsize=[10,5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGuSbO-C3YpW"
      },
      "source": [
        "### add simple moving average to data for n period"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HkKMQa_W3fLQ"
      },
      "outputs": [],
      "source": [
        "demand_df['SMA3'] = demand_df.demand.rolling(3).mean().shift(1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tqj0aiQIQgno"
      },
      "source": [
        "## Simple exponential smoothing = geen trend en geen seasonal component"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wrdpE1HfrkT"
      },
      "source": [
        "### Model opzetten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZqR8PmTSh4Y"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n",
        "data_ses = SimpleExpSmoothing(data['number_of_heavily_wounded']).fit(smoothing_level=0.1)\n",
        "data['SES'] = data_ses.fittedvalues"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_9XVrF0f0zA"
      },
      "source": [
        "### forecast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jipulgLNSn-b"
      },
      "outputs": [],
      "source": [
        "data_ses_fcast = data_ses.forecast(12)\n",
        "\n",
        "data.plot(y=['number_of_heavily_wounded',  'SES'], figsize=[10,5])\n",
        "data_ses_fcast.plot(marker='.', legend=True, label='Forecast')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJRRa6eGUgHA"
      },
      "source": [
        "## Double exponential smoothing = wel trend en geen seasonal component (Holt's)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMbFMPOGgCeU"
      },
      "source": [
        "### Model opzetten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "usnua03_UkNa"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa.api import Holt\n",
        "\n",
        "data_des = Holt(data['number_of_heavily_wounded']).fit(smoothing_level=.1, smoothing_trend=.2)\n",
        "\n",
        "data['DES'] = data_des.fittedvalues\n",
        "data.plot(y=['number_of_heavily_wounded',  'DES'], figsize=[10,5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAR6c70mgEJu"
      },
      "source": [
        "### Forecast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJIlmfYmgAvl"
      },
      "outputs": [],
      "source": [
        "data_des_fcast = data_des.forecast(12)\n",
        "\n",
        "data['number_of_heavily_wounded'].plot(marker='o', legend=True) # Observations\n",
        "data['DES'].plot(legend=True, label='DES fitted values', figsize=[10,5])              \n",
        "data_ses_fcast.plot(marker='.', legend=True, label='Forecast SES')\n",
        "data_des_fcast.plot(marker='.', legend=True, label='Forecast DES') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdxTHWr-eWg_"
      },
      "source": [
        "## Triple exponential smoothing = wel trend en wel seasonal component ( Holt's winter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKFjEqqigRsv"
      },
      "source": [
        "### Model opzetten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yy7IWuO_fDyu"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
        "\n",
        "train = data.number_of_heavily_wounded[:84]\n",
        "test = data.number_of_heavily_wounded[84:]\n",
        "\n",
        "model = ExponentialSmoothing(train,\n",
        "  trend='add', seasonal='add',\n",
        "  seasonal_periods=12, freq='MS').fit()\n",
        "\n",
        "train.plot(legend=True, label='train')\n",
        "test.plot(legend=True, label='test')\n",
        "model.fittedvalues.plot(legend=True, label='fitted')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NelAXN9AgUGr"
      },
      "source": [
        "### Forecast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hncGt9GxgV5N"
      },
      "outputs": [],
      "source": [
        "model_predicted = model.forecast(12)\n",
        "\n",
        "train.plot(legend=True, label='train')\n",
        "model.fittedvalues.plot(legend=True, label='fitted')\n",
        "\n",
        "test.plot(legend=True, label='test')\n",
        "model_predicted.plot(legend=True, label='predicted')\n",
        "\n",
        "plt.title('Train, test, fitted & predicted values using Holt-Winters')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vqCCvIekq2g"
      },
      "source": [
        "### Evaluating the quality of a model=   Mean Absolute Error (MAE) and Mean Squared Error (MSE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaoKoWuIkz7L"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
        "\n",
        "print(f'MAE = {mean_absolute_error(test,model_predicted)}')\n",
        "print(f'MSE = {mean_squared_error(test,model_predicted)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdpM9EXgk2sH"
      },
      "outputs": [],
      "source": [
        "print(f'√MSE  = {np.sqrt(mean_squared_error(test,model_predicted))}')\n",
        "print(f'stdev = {data.number_of_heavily_wounded.std()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBHu0oHWmASL"
      },
      "source": [
        "| √MSE vs stdev| interpretatie        |\n",
        "| :---:      | :---                    |\n",
        "|√MSE < stdev          | goed model       |\n",
        "| √MSE > stdev          | slecht model        |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ey6AJ35gP86b"
      },
      "source": [
        "hoe groter alpha => hoe meer de curve de waarnemingen volgt<br>\n",
        "hoe keliner alpha => hoe minder de curve de waarnemingen volgt"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
